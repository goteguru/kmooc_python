{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "I5K7wxvzr4_W"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goteguru/kmooc_python/blob/main/notebooks/en/kmooc_07_1_numpy_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NumPy\n",
        "\n",
        "Earlier we mentioned that Python is an interpreted language and (by default) uses only a single CPU core, so large-scale computations can be slow. The numpy package helps with this problem — it is a highly optimized array processing library.\n",
        "\n",
        "(By large-scale computation here we really mean large-scale: doing a few tens of thousands of operations on a few tens of thousands of numbers is not a problem for modern machines using basic Python, but inverting matrices of size tens of thousands by tens of thousands (hundreds of millions of elements) becomes problematic in an interpreted language.)\n",
        "\n",
        "This package is very popular in data processing, numerical modeling and artificial intelligence — practically a de facto standard. So it's useful to know what it can do and how it works.\n"
      ],
      "metadata": {
        "id": "TZIUI9rAWvBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first step: import the package!\nimport numpy as np\n# immediately renamed it to np (common convention) to type less.\n# So be sure to run this cell,\n# otherwise the others won't work at all."
      ],
      "metadata": {
        "id": "XXnjB8gaYwd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "K95i8Us1Cpch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_dimensional = np.array([1, 2, 3])\n",
        "two_dimensional = np.array([[1, 2], [3, 4]])"
      ],
      "metadata": {
        "id": "8GEDQmH1bG7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The one-dimensional array contains three rows (even though it prints side-by-side to fit better, they are rows).\n",
        "\n",
        "You can easily print arrays (for very large ones it prints only part) and query some useful information about them!"
      ],
      "metadata": {
        "id": "OmjZ5ufwbTg1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
        "print(\"number of dimensions:\", a.ndim)\n",
        "print(\"shape:\", a.shape)\n",
        "print(\"total elements:\" , a.size)\n",
        "print(\"data type:\", a.dtype)\n",
        "\n",
        "print(\"the array itself:\\n\", a)"
      ],
      "metadata": {
        "id": "l_T3se2bbcuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, an array has only one data type. This is in stark contrast to Python lists: a numpy array can only contain elements of the same type and fixed size — you cannot freely mix different types!\n",
        "\n",
        "This is actually good, because the elements can be accessed much faster. If every value occupies exactly the same amount of space, say 8 bytes, then the n-th value is exactly 8*n bytes away from the element at index zero.\n",
        "\n",
        "Although less common, arrays can also contain text. You just have to make sure they are of the same type. If not, NumPy (as a fallback) will try to convert them."
      ],
      "metadata": {
        "id": "QU22dAXIcJ05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(['Alfonz', 'Csilla', 'Viktor'])"
      ],
      "metadata": {
        "id": "bpeAmhWxDDUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(['Alfonz', 12, 0.34]) # these will become three strings, even though we provided numbers"
      ],
      "metadata": {
        "id": "_-0MvBKkDrGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you run the blocks above, you can see that it prints the dtype at the end. The U there means unicode data, and `<U6` means up to 6 codepoints (taking up six code units). NumPy determined this by looking at the longest element and formatting all elements to that length. NumPy array elements must have the same size, otherwise it couldn't jump quickly through the memory. So\n"
      ],
      "metadata": {
        "id": "iviQuxsB_BHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([\"a\", \"kobra\"])\n",
        "# let's see how much space the two elements and the whole np array occupy:\n",
        "len(arr[0].tobytes()), len(arr[1].tobytes()), len(arr.tobytes())"
      ],
      "metadata": {
        "id": "f7OgSljEASRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So even though the first element is a single character (4 bytes with unicode encoding and termination), because the second takes 20 bytes the first must also reserve that space (the remaining bytes are filled with zeros). In the end both occupy 20 bytes, so the total size is 40. This matters when you have millions of elements!\n",
        "\n",
        "Moreover, since NumPy guesses the element size from the initial values (which dtype would be best), if you later try to put a larger value in, it will be truncated!"
      ],
      "metadata": {
        "id": "2JpAAyHlCl5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr[0] = \"kerecsensólyom\"\n",
        "arr[0] # only the beginning fits, the rest gets truncated :-("
      ],
      "metadata": {
        "id": "KKqKfeZHDZGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, if you know you may have longer strings later, it's better to specify the size manually rather than relying on the heuristic!"
      ],
      "metadata": {
        "id": "N0EC1oxCEPzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([\"a\", \"kobra\"], dtype=\"<U200\")\n",
        "arr[0] = \"kerecsensólyom\"\n",
        "arr[0] # 200 unicode codepoints is plenty!"
      ],
      "metadata": {
        "id": "Yxmo71B2ECNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Array creation\n",
        "\n",
        "Often we need arrays with a specific structure but don't want to type them by hand: array-creation functions help here:"
      ],
      "metadata": {
        "id": "bg7XSwmkCxcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.zeros((2, 3))      # 2x3 \"all zeros\" array\n",
        "np.ones((3, 3))       # 3x3 ones\n",
        "np.full((2,2), 7)     # every element is 7\n",
        "np.eye(3)             # 3x3 identity matrix\n",
        "np.arange(0, 10, 2)   # 0–10 with step 2\n",
        "np.linspace(0, 1, 5)  # 5 equally spaced values in [0,1]\n",
        "np.random.random((2,2)) # 2x2 random numbers\n",
        "np.random.normal(size=20) # normal distribution (20 samples)\n",
        "np.random.lognormal(mean=0.0, sigma=1.0, size=10) # lognormal\n"
      ],
      "metadata": {
        "id": "edrMRM1TdKyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "... or we can reshape (rearrange) an existing array:"
      ],
      "metadata": {
        "id": "Umj424mhjT8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector = np.arange(0,36) # numbers 0-35 (a single long vector)\n",
        "print(vector)\n",
        "\n",
        "matrix = np.reshape(vector, (6,6)) # the same reshaped into a 6x6 matrix.\n",
        "print(matrix)\n",
        "\n",
        "flat = np.ravel(matrix) # flatten it again\n",
        "print(flat)"
      ],
      "metadata": {
        "id": "Yxp1UZmajbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the numbers of the \"vector\" were printed side-by-side to fit better, but they are actually rows. So it is a 36-row (vertical) matrix (vector)."
      ],
      "metadata": {
        "id": "qWzL80We9aj8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tens = np.arange(10,100,10)  # [10,20...90]\n",
        "ones_seq = np.arange(1,10) # [1,2,...9]\n",
        "\n",
        "print(np.hstack([tens, ones_seq])) # concatenate horizontally\n",
        "print(np.vstack([tens, ones_seq])) # concatenate vertically\n"
      ],
      "metadata": {
        "id": "Y1iAq5IK2O_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing\n",
        "\n",
        "NumPy arrays can be indexed with square brackets just like lists, but on turbo mode! Using commas* you can specify multiple dimensions (since arrays can be 2D, 3D or higher), and you can even filter with boolean values (masking).\n",
        "\n",
        "\\* Of course, we know that the comma actually denotes a tuple, so here it's really saying that NumPy can index its data structures with tuples."
      ],
      "metadata": {
        "id": "IFirMtVfhP8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = np.arange(1,17).reshape((4,4)) # 4x4 matrix\n",
        "\n",
        "print(m) # the whole matrix\n",
        "print(m[0,0]) # top-left corner\n",
        "print(m[-1,-1]) # bottom-right corner (same as [3,3], but from the end)\n",
        "print(m[1,3]) # second row, fourth element (indices start at 0)\n",
        "print(m[1:3]) # from second row up to the fourth (i.e. rows 2 and 3)"
      ],
      "metadata": {
        "id": "_2TxUHs4gH7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you omit a number on either side of the colon (range), it means \"from the start\" or \"to the end\" just like with lists. So if you omit both sides you get all elements. This is also true for lists, but with arrays it becomes more useful because they can be multi-dimensional and you might want all elements along the first axis but only a subset along the others!\n",
        "\n",
        "If instead of a simple index you pass a list (or tuple), you can request multiple indices at once."
      ],
      "metadata": {
        "id": "0cPVl8TDltcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(matrix[:,1]) # every row but only the 2nd column!\n",
        "print(\"-\"*30) # separator\n",
        "\n",
        "print(matrix[[0,9]]) # only the first and the last row\n",
        "print(\"-\"*30) # separator\n",
        "\n",
        "print(matrix[:,[0,9]]) # only the first and the last column\n",
        "# print(matrix[:,(0,9)]) # <--- could have written it like this as well"
      ],
      "metadata": {
        "id": "XUjsVSWolg3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Because any N-dimensional array can be considered as N+1-dimensional by inserting a new dimension of size one, NumPy allows us to insert dimensions (or \"axes\") anywhere. This becomes truly useful together with broadcasting rules (see below)."
      ],
      "metadata": {
        "id": "WFN7IZLP2gkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array([1,2,3,4])\n",
        "print(arr.shape) # this is four rows."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITS4tN3E3Prv",
        "outputId": "a586be02-2b23-4306-8c98-21f140324cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorized operations\n",
        "\n",
        "NumPy's real power is that you don't need to step through arrays element-by-element with relatively slow Python code; it can perform operations on the whole array \"at once\".\n",
        "\n",
        "In reality it doesn't do everything truly simultaneously, but with optimized code and by using multiple CPU cores it is significantly faster than writing explicit loops.\n",
        "\n",
        "Run these cells one after another:"
      ],
      "metadata": {
        "id": "2P3TB5ExoNQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1, 2, 3])\n",
        "a"
      ],
      "metadata": {
        "id": "t2LdJpxEoy1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a * 2         # array([2, 4, 6])\n"
      ],
      "metadata": {
        "id": "9UlFs9Vto6nA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a + 10        # array([11, 12, 13])"
      ],
      "metadata": {
        "id": "EkpPFe05o9wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a*a + 1"
      ],
      "metadata": {
        "id": "qlZ5unGjpgkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The regular Python math functions only work on scalars, so NumPy defines vectorized variants (sqrt, log, etc.) that work on arrays:"
      ],
      "metadata": {
        "id": "5J89UZKGqcoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.sqrt(a) # this is not the sqrt from the math module"
      ],
      "metadata": {
        "id": "MSYziV1JqrSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.log10(a) # base-10 logarithm"
      ],
      "metadata": {
        "id": "QD5gsr3wq1fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.pow(a,3) # cubes"
      ],
      "metadata": {
        "id": "T6pVM3k2rA2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So when you perform an operation, it applies to every element. The result does not even have to be numeric — it can be boolean, for example:"
      ],
      "metadata": {
        "id": "OF9fw5DRpF5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a > 2"
      ],
      "metadata": {
        "id": "_aPmlLA7pPUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the result array contains boolean values (True where the condition holds). At first this may not seem very useful, but it's extremely handy because NumPy arrays can be indexed with boolean arrays! In that case you get only the values where the boolean index is True."
      ],
      "metadata": {
        "id": "mGvzQWi9pzHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([10,20,30])\n",
        "a[[True, False, True]] # <- take the first, not the second, take the third.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTj5u0vYtx12",
        "outputId": "a98b6ecd-5d1b-4274-ef74-3da7545eaa4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([10, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.linspace(0,10,1000) # one thousand evenly spaced values between 0 and 10.\n",
        "# let's compute some wild function for every value:\n",
        "y = 2 * x*x * np.sin(2*x) + x - 1 # y = 2x² * sin(2x) + x - 1\n",
        "\n",
        "y<0 # At which points is y negative?\n",
        "y[y<0] # request all y values where y is negative."
      ],
      "metadata": {
        "id": "PWmKn5Mms8c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# numerical changes of y (approx):\n",
        "dy = np.diff(y) # increments (999 elements)\n",
        "y[1:][dy>3] # where did y increase by more than 3?\n"
      ],
      "metadata": {
        "id": "2Y7W1yPHutUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The multiplication operator (`*`) in NumPy means element-wise multiplication, not matrix multiplication. To avoid awkward calls to np.linalg.matmul, there is an operator for matrix multiplication: `@`. The transpose is also available as the .T attribute."
      ],
      "metadata": {
        "id": "zW9kluR2ESTM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = np.array([\n",
        "    [2,8],\n",
        "    [9,1],\n",
        "    [-2,3],\n",
        "    [4,-7],\n",
        "    [2,2],\n",
        "])\n",
        "print(vectors)\n",
        "# Gram matrix (all pairwise dot-products):\n",
        "vectors @ vectors.T"
      ],
      "metadata": {
        "id": "TEGUCWraFl1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute distances from the following coordinates!\n",
        "coords = np.array([\n",
        "    [1, 8],\n",
        "    [7, 12],\n",
        "    [1, 7],\n",
        "    [3, 9]\n",
        "])\n",
        "\n",
        "# d = ... <-- some computation"
      ],
      "metadata": {
        "id": "zzYPkvxoqKeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### solution:"
      ],
      "metadata": {
        "id": "I5K7wxvzr4_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = coords[:,0], coords[:,1]\n",
        "d = np.sqrt( x*x + y*y )\n",
        "\n",
        "# or:\n",
        "d = np.sqrt(x**2 + y**2)\n",
        "\n",
        "# or simply:\n",
        "d = np.linalg.norm(coords, axis=1)\n",
        "d"
      ],
      "metadata": {
        "id": "Z8eZndqPrqrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregations\n",
        "\n",
        "We can very quickly compute aggregations (sum, mean, max, etc.).\n",
        "\n"
      ],
      "metadata": {
        "id": "PSvSpqcJ0DN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([2,9,8,7,1])\n",
        "print(a.sum())\n",
        "print(a.mean()) # mean\n",
        "print(a.min()) # minimum element\n",
        "print(a.max())\n",
        "print(a.argmax())    # index of maximum element\n",
        "print(a.argmin())\n"
      ],
      "metadata": {
        "id": "Pq8sJi1J0UGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If the array is multi-dimensional, you can specify axes along which to aggregate:"
      ],
      "metadata": {
        "id": "S8nThPwA03Pn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = np.array([[1, 2, 3],\n",
        "              [4, 5, 6]])\n",
        "\n",
        "m.sum(axis=0)   # column-wise sums → [5, 7, 9]\n",
        "m.sum(axis=1)   # row-wise sums → [6, 15]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgEshmgF0_VX",
        "outputId": "3ef2a26c-0a94-4ab1-9991-145f2c76cded"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Broadcasting (expansion)\n",
        "\n",
        "NumPy automatically expands (\"broadcasts\") smaller arrays so that operations make sense. If the two arrays have the same shape, it performs element-wise operations. If an axis is missing on the smaller array, it repeats the smaller array along that axis as many times as needed.\n"
      ],
      "metadata": {
        "id": "-eD40IZM2-45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = np.array([[1,2,3],\n",
        "              [4,5,6]])\n",
        "\n",
        "v = np.array([10, 20, 30])\n",
        "\n",
        "m + v"
      ],
      "metadata": {
        "id": "j0547c2Y3OvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logically it actually does the same when operating with a constant:\n",
        "#\n",
        "a = np.array([1,2,3,4])\n",
        "\n",
        "print(a * [3,3,3,3])\n",
        "print(a * 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH3PXfpM4G8b",
        "outputId": "6efdf9fe-d969-4687-d267-1ec2a503eb6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 3  6  9 12]\n",
            "[ 3  6  9 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Broadcasting can be combined with axis-expansion, so we can easily compute combinations. If we intentionally insert a new axis, broadcasting will repeat elements along that axis, so we don't need to write loops!\n",
        "\n",
        "Here's an example: we have N values and want to compute differences (all pairwise combinations). We insert a new row axis once (which can be repeated), and a new column axis once (also repeated), so when we combine them we get all pairwise differences."
      ],
      "metadata": {
        "id": "aQEtYSl-yTb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values = np.array([1,5,15,40])\n",
        "\n",
        "values[None,:] - values[:,None]"
      ],
      "metadata": {
        "id": "Ug17uUGPywyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, actually we didn't strictly need to add the extra axis on the subtraction's first part, because they were already rows and broadcasting would have extended over the columns anyway, but this form may be easier to understand.\n",
        "\n",
        "Try removing the `values[None,:]` index."
      ],
      "metadata": {
        "id": "SfUfDjaV4rlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example\n",
        "\n",
        "Let's see how easily we can solve a two-dimensional linear regression:"
      ],
      "metadata": {
        "id": "f9xP28Np496Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data = np.array(\n",
        "            #x1                 x2            y\n",
        "       [[  75.375     ,    9.4453125 ,  125.00445389],\n",
        "       [  14.7421875 ,   32.3125    ,  -65.97093686],\n",
        "       [  63.96875   ,   87.375     , -132.55686565],\n",
        "       [  22.875     ,   61.        , -135.55599849],\n",
        "       [  70.8125    ,    4.7578125 ,  129.77077384],\n",
        "       [  58.9375    ,   85.625     , -138.95654107],\n",
        "       [   8.6953125 ,    4.62109375,    3.55415825],\n",
        "       [  50.78125   ,   62.6875    ,  -84.62982924],\n",
        "       [  42.53125   ,   19.125     ,   29.47322941],\n",
        "       [  89.        ,   32.625     ,   81.7848131 ]])\n"
      ],
      "metadata": {
        "id": "LDAaZI4B6ZIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xs = data[:, 0:2]\n",
        "y = data[:,2]\n",
        "\n",
        "# theoretical solution\n",
        "ginv = np.linalg.inv(xs.T @ xs)\n",
        "w = ginv @ xs.T @ y\n",
        "w # weights: ~2 and ~3\n"
      ],
      "metadata": {
        "id": "PFH6SdQd852z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Of course, instead of linear algebra we could have used an optimization routine:\n",
        "\n",
        "w = np.linalg.lstsq(xs, y)[0]\n",
        "w"
      ],
      "metadata": {
        "id": "WP5WmSsp-paJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# errors:\n",
        "errors = y - xs @ w\n",
        "print(errors)\n",
        "\n",
        "# sum of squared errors:\n",
        "np.sum(np.power(errors, 2))\n"
      ],
      "metadata": {
        "id": "bDdJw8y4Dh55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Computation speed\n",
        "\n",
        "NumPy not only yields more concise code (thanks to broadcasting rules) but is significantly faster due to its efficient C implementation."
      ],
      "metadata": {
        "id": "CEVgz3TQs21N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\nimport math # for distance calculations\nimport time # for timing\n",
        "\n",
        "# Let's compute lengths for two million (random) vectors\n",
        "N = 2_000_000\n",
        "rng = np.random.default_rng(0)\n",
        "x_np = rng.random(N)\n",
        "y_np = rng.random(N)\n",
        "\n",
        "# pure Python solution:\n",
        "x_py = x_np.tolist() # convert to python lists\n",
        "y_py = y_np.tolist()\n",
        "\n",
        "t0 = time.perf_counter() # measure only this part\n",
        "# the fastest pure-Python option is a list comprehension:\n",
        "r_py = [math.hypot(x_py[i], y_py[i]) for i in range(N)]\n",
        "t1 = time.perf_counter()\n",
        "\n",
        "# numpy solution:\n",
        "t2 = time.perf_counter()\n",
        "r_np = np.hypot(x_np, y_np)\n",
        "t3 = time.perf_counter()\n",
        "\n",
        "print(f\"Python: {t1 - t0:.3f}s\")\n",
        "print(f\"NumPy : {t3 - t2:.3f}s\")"
      ],
      "metadata": {
        "id": "ZEFoyjdxtGYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: if you run the timing cell several times, you may notice that NumPy can get even faster once it's \"warmed up\" (e.g. it has loaded the vectorized hypot implementation)."
      ],
      "metadata": {
        "id": "iWzORztOvWgd"
      }
    }
  ]
}
