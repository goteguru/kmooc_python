{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4wGCxZXsERFe"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/goteguru/kmooc_python/blob/main/notebooks/en/kmooc_08_1_pandas_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas\n",
        "\n",
        "If we're not working with purely numerical data but also have texts and categories, the de-facto Python library we reach for is `pandas`. This library has the computational capabilities of NumPy (it actually uses it) but extends it with many additional features:\n",
        "\n",
        "* categorical / text data\n",
        "* named columns\n",
        "* grouping\n",
        "* missing data handling\n",
        "\n",
        "So pandas provides functionality in Python similar to a spreadsheet with some database-like features.\n",
        "\n",
        "Combined with Python's very broad general capabilities, it can be a very powerful tool.\n",
        "\n"
      ],
      "metadata": {
        "id": "DVw9UXgm-rLz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSlhp9uk-Vry"
      },
      "outputs": [],
      "source": [
        "# we will need the pandas library,\n# so definitely run this.\n\nimport pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas has two fundamental data structures:\n",
        "\n",
        "* Series - one-dimensional data (like a column)\n",
        "* DataFrame - two-dimensional table (\"Excel\")\n",
        "\n",
        "## Series"
      ],
      "metadata": {
        "id": "48HtTZNFAhyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numbers = pd.Series([10, 20, 30, 40, 50])\nnumbers\n"
      ],
      "metadata": {
        "id": "e0x-A_7_A06O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "letters = pd.Series(['Alfa','Béta','Gamma'])\nletters"
      ],
      "metadata": {
        "id": "xM6p7-xhEOlU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that unlike NumPy arrays these structures always have an index (which is printed). If we want, we can inspect the index or the values themselves:"
      ],
      "metadata": {
        "id": "eiRtZV7pBI7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "letters.index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEhq4s8FBkRO",
        "outputId": "fc3114be-3e9e-409c-8075-3d427940f32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RangeIndex(start=0, stop=3, step=1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indexes are actually not stored as raw numbers (that wouldn't make much sense since they typically increase regularly), but a \"RangeIndex\" generator creates them for us if we want. It essentially only stores where it starts, where it ends, and the step size."
      ],
      "metadata": {
        "id": "REp4VsL9EwBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(letters.index) # force it to make a list"
      ],
      "metadata": {
        "id": "NaHLy6w2Efj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "letters.values # the values are normal values, of course."
      ],
      "metadata": {
        "id": "JgS6TTUPB4QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataFrame\n",
        "\n",
        "A DataFrame is more like an \"Excel\" table or a database table. Its columns have names. If we don't know the data, we don't provide them.\n",
        "\n",
        "Pandas is so fundamental that Colab (where you're viewing this) offers a special renderer for it. If you run the code below, it won't just print the values, it will nicely format them and provide tools. You can request chart suggestions or make an \"interactive\" (sortable, filterable) table. Since Colab provides this, running purely in the interpreter wouldn't give you these features (unless you use additional libraries)."
      ],
      "metadata": {
        "id": "jEbWlV6kFhkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table = pd.DataFrame({\n    \"name\": [\"Anna\", \"Béla\", \"Cecil\", \"Gábor\"],\n    \"age\": [23, 30, None ,27],\n    \"city\": [\"Budapest\", \"Szeged\", \"Pécs\", None]\n})\n\ntable"
      ],
      "metadata": {
        "id": "LIJZTGY2F1e9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try out what you can do with such a table!\n",
        "\n",
        "DataFrames also have attributes:\n"
      ],
      "metadata": {
        "id": "PQuTkGIzG3A9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "table.shape # there are four rows and three columns."
      ],
      "metadata": {
        "id": "Uq322m-_HdCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table.columns # these are the column names"
      ],
      "metadata": {
        "id": "muyWnj7uIGzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table.index # and of course there are indexes here too"
      ],
      "metadata": {
        "id": "STMRPzSeIWJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually we don't want to provide data by hand, but import it from some source (e.g., a spreadsheet) and then process it. Fortunately, we don't need to write special code for this: Pandas can easily read data from these files:"
      ],
      "metadata": {
        "id": "610gMiMyLxHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pd.read_csv(\"adat.csv\")  # from CSV file\n# pd.read_excel(\"adat.xlsx\") # from Excel format\n\n# or even from a url:\nurl = \"https://gist.githubusercontent.com/goteguru/2e1efde943f9c963dcbb1fcae598b646/raw/0c37ffa0c7fc2ee77a539101ea7986f21a141fa8/sample_people.csv\"\ndata = pd.read_csv(url)\ndata"
      ],
      "metadata": {
        "id": "t0R-vWIEMJW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pandas DataFrame not only resembles an Excel table, it can also handle it. We can easily read or write xlsx files. Try it! Upload an xlsx file (left-side menu) named data.xlsx (or change the filename in the code) and display its contents!"
      ],
      "metadata": {
        "id": "G1wV_EJ6IaI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"data.xlsx\"\ndf = pd.read_excel(file_name)\n\n# we can also write it to a file (locally in Colab):\ndf.to_excel(\"output.xlsx\", index=False)\n\n# or display it:\ndf"
      ],
      "metadata": {
        "id": "TgeyXzhxI53U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing\n",
        "\n",
        "Indexing is similar to what we saw with NumPy, but now we can also use column names."
      ],
      "metadata": {
        "id": "1Dehw2RMM91Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"age\"] # or like this\ndata.age # or even like this (if it doesn't contain spaces or special characters)"
      ],
      "metadata": {
        "id": "LcQkvwy1NIYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if we want multiple columns, provide them in a list\ndata[[\"city\", \"name\", \"age\"]] # we gave a list as an index!"
      ],
      "metadata": {
        "id": "Xy5afMdANZUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can access a specific row using the loc property\ndata.loc[2, \"name\"] # only the second row"
      ],
      "metadata": {
        "id": "lIEMM14POOJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[2:5, [\"name\",\"age\"]] # rows labeled from 2 to 5, the name and age fields."
      ],
      "metadata": {
        "id": "je4g7LKROiaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`.loc` looks at row labels, not positional indices. This is especially important if we've filtered the data. If you want to use positions (not labels), then:"
      ],
      "metadata": {
        "id": "JDzTNu9dWaUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[2:5] # instead of label, with the (0-based) index (third, fourth and fifth)"
      ],
      "metadata": {
        "id": "pNThg6ujVbNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.iloc[2:5] # but this is how it's usually written (iloc = indexed loc)"
      ],
      "metadata": {
        "id": "truHgK-NW2v1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conditional indexing\n",
        "\n",
        "Just like with NumPy, we can use boolean matrices as indices. This allows us to filter our data as we like:"
      ],
      "metadata": {
        "id": "aEEFNYvlx4rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[data.age<30]"
      ],
      "metadata": {
        "id": "3DTrdHe6yK83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[data.city == \"Budapest\"]"
      ],
      "metadata": {
        "id": "-jGgj9IiyY9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[(data.age > 30) & (data.city == \"Pécs\")]"
      ],
      "metadata": {
        "id": "NW7UxlF2yazA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Statistics\n",
        "\n",
        "As with databases, spreadsheets (or numpy), we can also work with aggregates."
      ],
      "metadata": {
        "id": "lqiF1_X0ynVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe() # statistics for all numeric fields"
      ],
      "metadata": {
        "id": "eZmNkiR0yzqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"age\"].mean() # mean\ndata[\"age\"].max()\ndata[\"age\"].min()\ndata[\"city\"].value_counts() # counts of values (how many of each)\n"
      ],
      "metadata": {
        "id": "uAmHMZP2y8-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"city\"].unique() # unique values (cities, each once)"
      ],
      "metadata": {
        "id": "N_0u7-i8zRXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"age\"].agg(['mean', 'min', 'max']) # compute multiple statistics at once"
      ],
      "metadata": {
        "id": "4Khuzvny4E4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modification\n",
        "\n",
        "If we want to add a new column or compute one, simply use a new index (column name) just like with a Python dict."
      ],
      "metadata": {
        "id": "72XcGVQ_zcyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\ncurrent_year = datetime.now().year\n\ndata[\"birth_year\"] = current_year - data[\"age\"]\ndata"
      ],
      "metadata": {
        "id": "aKm0bCjWzpXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(columns=[\"birth_year\"]) # a copy without that column"
      ],
      "metadata": {
        "id": "xtNmLGmR0lVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"name_length\"] = data[\"name\"].apply(len) # apply the len function to every name\ndata"
      ],
      "metadata": {
        "id": "FOgUjmfB04s9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling missing values\n",
        "\n"
      ],
      "metadata": {
        "id": "yInJ_N1X1HJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna() # where is data missing?"
      ],
      "metadata": {
        "id": "YQRFx8X71Lwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isna().sum() # how many are there?"
      ],
      "metadata": {
        "id": "RRwiDI0D1SiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Missing data often needs to be handled in some way. For example, we could drop rows with missing values (not ideal) or fill them somehow, e.g., with the mean or the mode."
      ],
      "metadata": {
        "id": "XbTlZl5Y17mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna() # drop rows where data is missing"
      ],
      "metadata": {
        "id": "nzJgdHvs2YBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"age\"].fillna(data[\"age\"].mean()) # fill missing with the mean"
      ],
      "metadata": {
        "id": "e-5fJPSV2MbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modify the above code so that instead of the whole table it only prints the `.shape` attribute, so you can see how many rows remain!"
      ],
      "metadata": {
        "id": "D1lDVkeO2ju-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sorting and grouping\n",
        "\n",
        "One useful capability of database systems is fast grouping and sorting. Pandas DataFrame can do this too."
      ],
      "metadata": {
        "id": "ga7VQIkP2vsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.sort_index() # by row number\ndata.sort_values(\"age\") # by age\ndata.sort_values(\"age\", ascending=False) # in descending order"
      ],
      "metadata": {
        "id": "Drb38MJI27Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the average age per city?\ndata.groupby(\"city\")[\"age\"].mean()"
      ],
      "metadata": {
        "id": "gT7ezDvq3QPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What is the median height by gender?\ndata.groupby(\"gender\")[\"height\"].median()"
      ],
      "metadata": {
        "id": "S4TngmEP_HVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute multiple statistics per city:\ndata.groupby(\"city\").agg({\n    \"age\": \"mean\",\n    \"name\": \"count\"\n})\n"
      ],
      "metadata": {
        "id": "j72NNAOS3bBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Joining DataFrames\n",
        "\n",
        "Often our data is not in a single table, but there is a relation between tables and we can match rows based on some key. For example, we might have another table with additional data about cities (e.g., area), so if we know a person's city from the residents table, we can also know the area of that municipality. (If you've worked with databases this will be familiar.) Pandas can also join DataFrames."
      ],
      "metadata": {
        "id": "se6Md_8f4f8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cities = pd.DataFrame({\n    \"city\": [\"Budapest\", \"Pécs\", \"Debrecen\", \"Szeged\", \"Győr\"],\n    \"area\": [525.14, 162.78, 461.66, 281.00, 174.62]\n})\n\n# the join is provided by the city field\ndata.merge(cities, on=\"city\", how=\"left\")"
      ],
      "metadata": {
        "id": "Co28PRbM5xUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the example above, `how=\"left\"` may be familiar from SQL. It means we want a LEFT JOIN, so if a person doesn't have a city specified (missing), we still want them to appear in the result (they just won't have an area).\n\nIf we request an INNER JOIN, only rows that appear in both tables will be shown."
      ],
      "metadata": {
        "id": "udILc_3I68eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(\n    len(data), # how big (how many rows) was the original?\n    len(data.merge(cities, on=\"city\", how=\"left\")), # how many rows with left join?\n    len(data.merge(cities, on=\"city\")), # and how many with inner join?\n)"
      ],
      "metadata": {
        "id": "8X6HEHci7cv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the field used for joining is not named the same (unlike now), then:\ndata.merge(cities, left_on=\"city\", right_on=\"city\", how=\"left\")"
      ],
      "metadata": {
        "id": "nfEuFICoABso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Persisting data\n",
        "\n",
        "When the Python program ends, the data in the DataFrame is lost. Of course we can save it to CSV or XLSX, but let's learn a better option. If you plan to use the saved data later with Pandas or modern data tools, parquet is a good choice. It's fast, compact and an efficient binary data format. (Feather is another alternative.)\n\nSaving data is super easy:"
      ],
      "metadata": {
        "id": "_46qwI_rnUY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save:\ndata.to_parquet(\"adatok.parquet\")\n\n# read back:\nrestored = pd.read_parquet(\"adatok.parquet\")"
      ],
      "metadata": {
        "id": "8Thmzol_oDnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization\n",
        "\n",
        "Pandas has built-in visualization (by default it uses Matplotlib) so we can quickly display our data. \n",
        "\n"
      ],
      "metadata": {
        "id": "KWfRqUAu8X9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the heights for me\ndata[\"height\"].plot()"
      ],
      "metadata": {
        "id": "aMBoIWJMAkgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# age \"distribution\" (histogram), split into 20 bins\ndata['age'].plot.hist(bins=20)"
      ],
      "metadata": {
        "id": "zHd1ILRk8pWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# average height per city, as a bar chart:\ndata.groupby(\"city\")[\"height\"].mean().plot(kind=\"bar\")"
      ],
      "metadata": {
        "id": "VRgu5iaX9AN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# per gender, how many people have a city specified?\ndata.groupby(\"gender\").count()[\"city\"].plot(kind=\"pie\")"
      ],
      "metadata": {
        "id": "3QDucNBkAyX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of people per city:"
      ],
      "metadata": {
        "id": "whZsrsl6CXUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to compute (and maybe plot) the following:\n",
        "\n",
        "- How many women (F) are in our data?\n- How many rows have no city specified?\n- How many people are there per city?\n- What is the average height of people per city?\n- Average area of residence by gender?\n- What is the average of the product of people's age and their city's area? (don't ask what that's useful for :))\n\nIf you get stuck, AI can help.\n"
      ],
      "metadata": {
        "id": "YLDLd-cxCkpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your solutions:"
      ],
      "metadata": {
        "id": "63E7_r_xEPEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Solutions:"
      ],
      "metadata": {
        "id": "4wGCxZXsERFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(data[data[\"gender\"]==\"F\"]) # how many women (could be done differently)\ndata[\"city\"].isna().sum() # how many rows have no city specified?\ndata['city'].value_counts() # how many people per city\ndata.groupby('city')['height'].mean() # average height per city\n\ndata_with_cities = data.merge(cities, on=\"city\")\n# average area of residence by gender\ndata_with_cities.groupby(\"gender\")[\"area\"].mean()\n\n# average of people's age multiplied by their city's area?\n(data_with_cities[\"age\"] * data_with_cities[\"area\"]).mean()"
      ],
      "metadata": {
        "id": "AoezieNSCZ4k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
